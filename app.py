import streamlit as st
import requests
import json
import os
import re
from pypdf import PdfReader

st.set_page_config(page_title="Nelson Auto-Expert", page_icon="К", layout="wide")
st.title("К Nelson AI: 住专拽 驻 ")

# -IDs 砖
RAW_FILES = {
    "Part A": "1QAcPOd_EZnIMN9AZKFhXTPycQb_3XtHa",
    "Part B": "1XgAmPZRspaFixuwZRUA9WRDtJe7UfGX6",
    "Part C": "1iEukcQ443jQeG35u4zSENFb_9vkhiCtx",
    "Part D": "1rgucmtUfSN6wUzpyptOilOi4LVykQQnt",
    "Part E": "1ru9-fs1MnTaa5vJzNV1sryj0hRxPy3_v",
}

def download_file(f_id, name):
    path = f"{name}.pdf"
    if not os.path.exists(path):
        url = f'https://drive.google.com/uc?id={f_id}&export=download'
        r = requests.get(url)
        with open(path, 'wb') as f:
            f.write(r.content)
    return path

# --- 驻拽爪转 拽住: 住专拽,  住专 ---
@st.cache_resource
def get_sorted_library():
    library = []
    status_text = st.empty()
    
    for label, f_id in RAW_FILES.items():
        status_text.text(f" 住专拽 转 {label}...")
        path = download_file(f_id, label)
        reader = PdfReader(path)
        
        # 驻砖 住驻专 注 驻住 注 专砖 (专  注  )
        first_page_text = reader.pages[0].extract_text()
        found_numbers = re.findall(r'\b\d{1,4}\b', first_page_text)
        # 拽 转 住驻专 砖 住专 砖 住驻专 注
        detected_page = int(found_numbers[-1]) if found_numbers else 1
        
        library.append({
            "original_label": label,
            "path": path,
            "start_page": detected_page,
            "total_pages": len(reader.pages)
        })
    
    #  专 驻 住驻专 注 砖爪
    sorted_lib = sorted(library, key=lambda x: x['start_page'])
    
    # 注 砖转 -Part 1, Part 2 '
    for i, item in enumerate(sorted_lib):
        item['final_name'] = f"Part {i+1}"
        
    status_text.empty()
    return sorted_lib

# --- 驻拽爪转 Gemini ---
def ask_nelson(topic, lib_context):
    api_key = st.secrets["GOOGLE_API_KEY"].strip()
    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key={api_key}"
    
    prompt = f"""
    You are a Senior Pediatric Researcher. I have a library of Nelson 22nd Ed divided into 5 PDFs.
    Here is the mapping of my files:
    {lib_context}
    
    TOPIC: {topic}
    
    TASK:
    1. Conduct a deep medical review of this topic.
    2. Provide a mapping table:
       - Chapter Name | Chapter Number
       - Printed Page: The actual number on the book page.
       - PDF Location: Which 'Part X' and what is the 'PDF Page Index' (Printed Page - File Start Page + 1).
    
    Language: Hebrew prose, English medical terms.
    """
    
    payload = {"contents": [{"parts": [{"text": prompt}]}]}
    res = requests.post(url, json=payload)
    return res.json()['candidates'][0]['content']['parts'][0]['text']

# --- 砖拽 砖转砖 ---
if 'library' not in st.session_state:
    if st.button(" 驻注 住专拽 住专 住驻专 (爪注 驻注 转)"):
        st.session_state['library'] = get_sorted_library()
        st.success("住驻专 住专 专转!")

if 'library' in st.session_state:
    st.sidebar.header(" 住专 住驻专 (专):")
    lib_summary = ""
    for item in st.session_state['library']:
        st.sidebar.write(f"**{item['final_name']}**: 注 {item['start_page']} 注 {item['start_page'] + item['total_pages']}")
        lib_summary += f"{item['final_name']} (File: {item['path']}) starts at page {item['start_page']}. "

    topic = st.text_input(" 砖 拽专 (砖: Bronchiolitis):")
    if st.button("爪注 拽专 注拽"):
        with st.spinner("驻专驻住专 住专拽 转 注..."):
            result = ask_nelson(topic, lib_summary)
            st.markdown("---")
            st.markdown(result)
