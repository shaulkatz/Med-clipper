import streamlit as st
import json, urllib.request, time, io, re
from pypdf import PdfReader, PdfWriter

st.set_page_config(page_title="Med Clipper Pro", page_icon="")
st.title(" Med Clipper Pro")

# 砖转 驻转
try:
    api_key = st.secrets["GOOGLE_API_KEY"]
except:
    st.error(" 爪 驻转 -Secrets")
    st.stop()

uploaded_file = st.file_uploader("注 拽抓 PDF", type="pdf")
topic = st.text_input("砖 驻砖 (砖: T-cell deficiency):")

def ask_gemini(prompt):
    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={api_key}"
    data = json.dumps({"contents": [{"parts": [{"text": prompt}]}]}).encode()
    req = urllib.request.Request(url, data=data, headers={'Content-Type': 'application/json'})
    try:
        with urllib.request.urlopen(req) as res:
            return json.loads(res.read())['candidates'][0]['content']['parts'][0]['text']
    except: return "None"

if st.button("爪注 驻砖 注拽"):
    if uploaded_file and topic:
        reader = PdfReader(uploaded_file)
        total_pages = len(reader.pages)
        
        # 拽 转 驻砖
        search_words = topic.lower().replace('-', ' ').split()
        
        with st.spinner("住专拽 转 住驻专 驻砖 砖..."):
            found_in_pages = []
            map_data = ""
            
            for i in range(total_pages):
                text = reader.pages[i].extract_text()
                if text:
                    # 拽 拽住 注 爪专 驻砖
                    clean_text = text.lower().replace('-', ' ')
                    # 拽  专 转 驻砖 驻注转 注
                    match_count = sum(1 for word in search_words if word in clean_text)
                    
                    if match_count >= len(search_words) * 0.7: # 转 砖 70% 
                        found_in_pages.append(i + 1)
                        if len(map_data) < 35000:
                            map_data += f"\n[PAGE_{i+1}] {text[:1500]}\n"
            
            if not found_in_pages:
                st.error(f" 爪转 转 '{topic}'. 住 驻砖  转 专转  'T-Cell'  'Immunodeficiency'.")
            else:
                st.info(f" 爪 专 专 -{len(found_in_pages)} 注.")
                
                prompt = f"""
                Analyze these textbook snippets. We are looking for the chapter on '{topic}'.
                 mentios found on pages: {found_in_pages}.
                Snippets:
                {map_data}
                
                What is the full start and end PDF page range of this chapter? 
                Return ONLY 'start-end'.
                """
                
                ans = ask_gemini(prompt).strip()
                nums = re.findall(r'\d+', ans)
                
                if len(nums) >= 2:
                    start_p, end_p = int(nums[0]), int(nums[1])
                    start_p, end_p = max(1, start_p - 1), min(total_pages, end_p + 3)
                    
                    st.success(f"驻专拽 转专! 注 {start_p} 注 {end_p}")
                    writer = PdfWriter()
                    for p in range(start_p - 1, end_p):
                        writer.add_page(reader.pages[p])
                    
                    output = io.BytesIO()
                    writer.write(output)
                    st.download_button(f" 专 驻专拽: {topic}", output.getvalue(), f"{topic}.pdf")
                else:
                    st.warning("-AI  爪 专  拽,  专 转 注 砖爪.")
                    writer = PdfWriter()
                    for p_num in found_in_pages[:30]:
                        writer.add_page(reader.pages[p_num-1])
                    output = io.BytesIO()
                    writer.write(output)
                    st.download_button(" 专 注 专", output.getvalue(), "results.pdf")
